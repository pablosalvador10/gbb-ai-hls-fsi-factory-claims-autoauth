import os
from typing import Any, Dict, List, Optional

from azure.core.credentials import AzureKeyCredential
from azure.search.documents import SearchClient
from azure.search.documents.models import (
    QueryAnswerType,
    QueryCaptionType,
    QueryType,
    VectorizableTextQuery,
)

from src.aoai.aoai_helper import AzureOpenAIManager
from src.documentintelligence.document_intelligence_helper import (
    AzureDocumentIntelligenceManager,
)
from src.pipeline.promptEngineering.prompt_manager import PromptManager
from src.pipeline.utils import load_config
from src.storage.blob_helper import AzureBlobManager
from utils.ml_logging import get_logger


class AgenticRAG:
    """
    Enhanced Retrieval-Augmented Generation (RAG) pipeline with sequential processing:
    1. Query Expansion
    2. Policy Retrieval
    3. Evaluation with retries if necessary.
    """

    def __init__(
        self,
        config_file: str = os.path.join("agenticRag", "settings.yaml"),
        azure_openai_client: Optional[AzureOpenAIManager] = None,
        prompt_manager: Optional[PromptManager] = None,
        search_client: Optional[SearchClient] = None,
        azure_blob_manager: Optional[AzureBlobManager] = None,
        document_intelligence_client: Optional[AzureDocumentIntelligenceManager] = None,
        caseId: Optional[str] = None,
    ) -> None:
        self.config = load_config(config_file)
        self.run_config = self.config.get("run", {})
        self.query_expansion_config = self.config.get("query_expansion", {})
        self.policy_retrieval_config = self.config.get("retrieval", {})
        self.evaluation_config = self.config.get("evaluation", {})
        self.caseId = caseId
        self.prefix = f"[caseID: {self.caseId}] " if self.caseId else ""

        self.logger = get_logger(
            name=self.run_config["logging"]["name"],
            level=self.run_config["logging"]["level"],
            tracing_enabled=self.run_config["logging"]["enable_tracing"],
        )

        if azure_openai_client is None:
            api_key = os.getenv("AZURE_OPENAI_KEY", None)
            if api_key is None:
                self.logger.warning("No AZURE_OPENAI_KEY found. AgenticRAG may fail.")
            azure_openai_client = AzureOpenAIManager(api_key=api_key)
        self.azure_openai_client = azure_openai_client

        self.prompt_manager = prompt_manager or PromptManager()

        if search_client is None:
            endpoint = os.getenv("AZURE_AI_SEARCH_SERVICE_ENDPOINT")
            index_name = os.getenv("AZURE_SEARCH_INDEX_NAME")
            azure_search_admin_key = os.getenv("AZURE_AI_SEARCH_ADMIN_KEY")
            search_client = SearchClient(
                endpoint=endpoint,
                index_name=index_name,
                credential=AzureKeyCredential(azure_search_admin_key),
            )
        self.search_client = search_client

        self.blob_manager = azure_blob_manager or AzureBlobManager(
            storage_account_name=os.getenv("AZURE_STORAGE_ACCOUNT_NAME"),
            account_key=os.getenv("AZURE_STORAGE_ACCOUNT_KEY"),
            container_name=self.run_config["azure_blob"]["container_name"],
        )

        self.document_intelligence_client = (
            document_intelligence_client
            or AzureDocumentIntelligenceManager(
                azure_endpoint=os.getenv("AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT"),
                azure_key=os.getenv("AZURE_DOCUMENT_INTELLIGENCE_KEY"),
            )
        )

    async def expand_query(
        self,
        clinical_info: Any,
        system_message_content: Optional[str] = None,
        max_tokens: Optional[int] = None,
        top_p: Optional[float] = None,
        temperature: Optional[float] = None,
        frequency_penalty: Optional[float] = None,
        presence_penalty: Optional[float] = None,
    ) -> str:
        """
        Expands the user-provided clinical information into an optimized query.

        Args:
            clinical_info (Any): Input clinical information.
            system_message_content (Optional[str]): System message content for the prompt. Defaults to self.SYSTEM_PROMPT_QUERY_EXPANSION.
            max_tokens (Optional[int]): Maximum number of tokens for the response. Defaults to self.max_tokens.
            top_p (Optional[float]): Top-p sampling parameter. Defaults to self.top_p.
            temperature (Optional[float]): Sampling temperature. Defaults to self.temperature.
            frequency_penalty (Optional[float]): Frequency penalty. Defaults to self.frequency_penalty.
            presence_penalty (Optional[float]): Presence penalty. Defaults to self.presence_penalty.

        Returns:
            str: Expanded query.
        """
        self.logger.info(f"{self.prefix}Expanding query...")

        # Use provided values or default to self attributes
        system_message_content = (
            system_message_content
            or self.prompt_manager.get_prompt(
                self.query_expansion_config["system_prompt"]
            )
        )
        max_tokens = max_tokens or self.query_expansion_config["max_tokens"]
        top_p = top_p or self.query_expansion_config["top_p"]
        temperature = temperature or self.query_expansion_config["temperature"]
        frequency_penalty = (
            frequency_penalty or self.query_expansion_config["frequency_penalty"]
        )
        presence_penalty = (
            presence_penalty or self.query_expansion_config["presence_penalty"]
        )

        prompt = self.prompt_manager.create_prompt_formulator_user(clinical_info)
        response = await self.azure_openai_client.generate_chat_response(
            query=prompt,
            system_message_content=system_message_content,
            conversation_history=[],
            response_format="json_object",
            max_tokens=max_tokens,
            top_p=top_p,
            temperature=temperature,
            frequency_penalty=frequency_penalty,
            presence_penalty=presence_penalty,
        )
        return response.get("response", {}).get("optimized_query", "")

    def _format_azure_search_results(self, results: list, truncate: int = 2000) -> str:
        """
        Formats Azure AI Search results into a structured, readable string.

        Each result contains:
        - Chunk ID
        - Reranker Score
        - Source Document Path
        - Content (truncated to the specified number of characters if too long)
        - Caption (highlighted if available)

        :param results: List of results from the Azure AI Search API.
        :param truncate: Maximum number of characters to include in the content before truncating.
        :return: Formatted string representation of the search results.
        """
        formatted_results = []

        for result in results:
            # Access all properties like a dictionary
            chunk_id = result["chunk_id"] if "chunk_id" in result else "N/A"
            reranker_score = (
                result["@search.reranker_score"]
                if "@search.reranker_score" in result
                else "N/A"
            )
            source_doc_path = (
                result["parent_path"] if "parent_path" in result else "N/A"
            )
            content = result["chunk"] if "chunk" in result else "N/A"

            # Truncate content to specified number of characters
            content = content[:truncate] + "..." if len(content) > truncate else content

            # Extract caption (highlighted caption if available)
            captions = (
                result["@search.captions"] if "@search.captions" in result else []
            )
            caption = "Caption not available"
            if captions:
                first_caption = captions[0]
                if first_caption.highlights:
                    caption = first_caption.highlights
                elif first_caption.text:
                    caption = first_caption.text

            # Format each result section
            result_string = (
                f"========================================\n"
                f"ðŸ†” ID: {chunk_id}\n"
                f"ðŸ“‚ Source Doc Path: {source_doc_path}\n"
                f"ðŸ“œ Content: {content}\n"
                f"ðŸ’¡ Caption: {caption}\n"
                f"========================================"
            )

            formatted_results.append(result_string)

        # Join all the formatted results into a single string
        return "\n\n".join(formatted_results)

    def retrieve_policies(
        self,
        query: str,
        k_nearest_neighbors: Optional[int] = None,
        weight: Optional[float] = None,
        top: Optional[int] = None,
        semantic_config: Optional[str] = None,
        vector_field: Optional[str] = None,
    ) -> List[Dict[str, Any]]:
        """
        Retrieves policies based on the expanded query.

        Args:
            query (str): Expanded query.
            k_nearest_neighbors (Optional[int]): Number of nearest neighbors to retrieve. Defaults to 5.
            weight (Optional[float]): Weight for the vector query. Defaults to 0.5.
            top (Optional[int]): Number of top results to retrieve. Defaults to 5.
            semantic_config (Optional[str]): Semantic configuration name. Defaults to "my-semantic-config".
            vector_field (Optional[str]): Fields to use for the vector query. Defaults to "vector".

        Returns:
            List[Dict[str, Any]]: Retrieved policy documents.
        """
        self.logger.info(f"{self.prefix}Retrieving policies...")
        semantic_config = (
            self.policy_retrieval_config["semantic_configuration_name"]
            or semantic_config
        )
        vector_field = self.policy_retrieval_config["vector_field"] or vector_field
        k_nearest_neighbors = (
            self.policy_retrieval_config["k_nearest_neighbors"] or k_nearest_neighbors
        )
        weight = self.policy_retrieval_config["weight"] or weight
        top = self.policy_retrieval_config["top"] or top

        vector_query = VectorizableTextQuery(
            text=query,
            k_nearest_neighbors=k_nearest_neighbors,
            fields=vector_field,
            weight=weight,
        )
        results = self.search_client.search(
            search_text=query,
            vector_queries=[vector_query],
            query_type=QueryType.SEMANTIC,
            semantic_configuration_name=semantic_config,
            query_caption=QueryCaptionType.EXTRACTIVE,
            query_answer=QueryAnswerType.EXTRACTIVE,
            top=top,
        )
        return self._format_azure_search_results(results, truncate=2000)

    async def evaluate_results(
        self,
        query: str,
        search_results: List[Dict[str, Any]],
        system_message_content: Optional[str] = None,
        max_tokens: Optional[int] = None,
        top_p: Optional[float] = None,
        temperature: Optional[float] = None,
        frequency_penalty: Optional[float] = None,
        presence_penalty: Optional[float] = None,
    ) -> Dict[str, Any]:
        """
        Evaluates the search results using Azure OpenAI.

        Args:
            query (str): Original user query.
            search_results (List[Dict[str, Any]]): Retrieved search results.
            system_message_content (Optional[str]): System message content for the prompt.
            conversation_history (Optional[List[Dict[str, Any]]]): Conversation history for the prompt. Defaults to an empty list.
            response_format (str): Format of the response. Defaults to "json_object".
            max_tokens (Optional[int]): Maximum number of tokens for the response. Defaults to self.max_tokens.
            top_p (Optional[float]): Top-p sampling parameter. Defaults to self.top_p.
            temperature (Optional[float]): Sampling temperature. Defaults to self.temperature.
            frequency_penalty (Optional[float]): Frequency penalty. Defaults to self.frequency_penalty.
            presence_penalty (Optional[float]): Presence penalty. Defaults to self.presence_penalty.

        Returns:
            Dict[str, Any]: Evaluation results with policies, reasoning, and retry flag.
        """
        self.logger.info(f"{self.prefix}Evaluating search results...")

        # Use provided values or default to self attributes
        system_message_content = (
            system_message_content
            or self.prompt_manager.get_prompt(
                self.query_expansion_config["system_prompt"]
            )
        )
        max_tokens = max_tokens or self.query_expansion_config["max_tokens"]
        top_p = top_p or self.query_expansion_config["top_p"]
        temperature = temperature or self.query_expansion_config["temperature"]
        frequency_penalty = (
            frequency_penalty or self.query_expansion_config["frequency_penalty"]
        )
        presence_penalty = (
            presence_penalty or self.query_expansion_config["presence_penalty"]
        )

        prompt = self.prompt_manager.create_prompt_evaluator_user(query, search_results)
        response = await self.azure_openai_client.generate_chat_response(
            query=prompt,
            system_message_content=system_message_content,
            conversation_history=[],
            response_format="json_object",
            max_tokens=max_tokens,
            top_p=top_p,
            temperature=temperature,
            frequency_penalty=frequency_penalty,
            presence_penalty=presence_penalty,
        )
        self.logger.info(
            f"""{self.prefix}/n Evaluation response:
                         {response.get('response', {})}"""
        )
        return response.get(
            "response", {"policies": [], "reasoning": [], "retry": True}
        )

    async def run(self, clinical_info: Any, max_retries: int = 3) -> Dict[str, Any]:
        """
        Orchestrates the complete RAG process:
        1. Query Expansion
        2. Policy Retrieval
        3. Evaluation
        with retries if necessary and minimal error handling.

        Args:
            clinical_info (Any): User-provided clinical information.
            max_retries (int): Maximum number of retries for the process. Default is 3.

        Returns:
            Dict[str, Any]: Dictionary containing the query, policies found, and evaluation results.
        """

        for attempt in range(max_retries):
            self.logger.info(
                f"{self.prefix}Starting AgenticRAG attempt {attempt + 1} of {max_retries}"
            )
            try:
                # Step 1: Query Expansion
                expanded_query = await self.expand_query(clinical_info)
                if not expanded_query:
                    self.logger.warning(
                        f"{self.prefix}Query expansion failed. Retrying..."
                    )
                    continue

                self.logger.info(f"{self.prefix}Expanded Query: {expanded_query}")

                # Step 2: Policy Retrieval
                search_results = self.retrieve_policies(expanded_query)
                if not search_results:
                    self.logger.warning(
                        f"{self.prefix}No search results found. Retrying..."
                    )
                    continue

                self.logger.info(f"{self.prefix}Search results retrieved successfully")

                # Step 3: Evaluation
                evaluation = await self.evaluate_results(expanded_query, search_results)
                if not evaluation.get("retry", True):
                    self.logger.info(
                        f"{self.prefix}Evaluation successful. Policies: {evaluation.get('policies', [])}"
                    )
                    return {
                        "query": expanded_query,
                        "policies": evaluation.get("policies", []),
                        "evaluation": evaluation,
                    }

                self.logger.info(
                    f"{self.prefix}Evaluation retry flag set to true. Retrying..."
                )
            except Exception as e:
                self.logger.error(
                    f"{self.prefix}An unexpected error occurred on attempt {attempt + 1} of {max_retries}: {e}. Retrying..."
                )
                continue

        self.logger.error(
            f"{self.prefix}Max retries reached. Returning empty list of policies."
        )
        return {"query": None, "policies": [], "evaluation": None}
